# ğŸ‰ Instructions finales - Job Ad Scraper

## ğŸ“‚ Structure du projet

```
JobAdScrapper/
â”œâ”€â”€ ğŸŒ app.py                    # Interface web Flask
â”œâ”€â”€ ğŸ¤– main.py                   # Scraper principal
â”œâ”€â”€ âš™ï¸ config.yaml               # Configuration personnalisÃ©e
â”œâ”€â”€ ğŸ“„ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ ğŸ—„ï¸ jobs.db                   # Base de donnÃ©es SQLite (auto-crÃ©Ã©e)
â”œâ”€â”€ ğŸ“ templates/                # Templates HTML pour l'interface web
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ jobs.html
â”‚   â”œâ”€â”€ config.html
â”‚   â””â”€â”€ sessions.html
â”œâ”€â”€ ğŸš€ start_scraper.sh          # Script scraper en ligne de commande
â”œâ”€â”€ ğŸŒ start_web.sh/bat          # Scripts interface web
â”œâ”€â”€ ğŸ“š README.md                 # Documentation complÃ¨te
â”œâ”€â”€ ğŸ¯ USAGE.md                  # Guide d'utilisation
â””â”€â”€ ğŸŒ WEB_INTERFACE.md          # Documentation interface web
```

## ğŸš€ DÃ©marrage rapide

### Option 1 : Interface Web (RECOMMANDÃ‰E)
```bash
# Lancer l'interface web
./start_web.sh

# AccÃ©der Ã  l'interface
open http://localhost:5000
```

### Option 2 : Ligne de commande
```bash
# Lancer le scraper traditionnel
./start_scraper.sh
```

## ğŸ¯ Utilisation de l'interface web

### 1. **DÃ©marrage** 
```bash
./start_web.sh
```

### 2. **Configuration**
- Allez sur http://localhost:5000/config
- Modifiez vos critÃ¨res (compÃ©tences, localisation, salaire)
- Cliquez sur "Sauvegarder"

### 3. **Lancement du scraping**
- Retour sur http://localhost:5000
- Cliquez sur "DÃ©marrer le scraping"
- Suivez la progression en temps rÃ©el

### 4. **Consultation des rÃ©sultats**
- Page "Offres" : Tous les rÃ©sultats avec filtres
- Tri par score de compatibilitÃ©
- Liens directs vers les offres

### 5. **Historique**
- Page "Historique" : Toutes les sessions
- Statistiques et graphiques
- Analyse des performances

## ğŸ”§ Configuration recommandÃ©e

Votre configuration actuelle est optimisÃ©e pour :
- **Profil** : IngÃ©nieur logiciel / Full Stack
- **Zones** : Suisse romande, Lille, TÃ©lÃ©travail
- **Salaires** : 60k-120kâ‚¬ par an
- **CompÃ©tences** : Python, JavaScript, React, Docker, AWS...

## ğŸ—„ï¸ Base de donnÃ©es SQLite

### Avantages
- **Persistance** : Vos donnÃ©es sont sauvegardÃ©es
- **Performance** : Recherche rapide avec index
- **DÃ©duplication** : Pas de doublons d'offres
- **Historique** : Suivi des sessions

### Localisation
- Fichier : `jobs.db`
- Sauvegarde : Copiez simplement le fichier

## ğŸ“Š FonctionnalitÃ©s clÃ©s

### Interface web
- âœ… **Tableau de bord** : Statistiques temps rÃ©el
- âœ… **Progression** : Suivi temps rÃ©el du scraping
- âœ… **Filtres** : Tri par score, entreprise, date
- âœ… **Configuration** : Ã‰diteur YAML intÃ©grÃ©
- âœ… **Historique** : Sessions avec graphiques

### Scraping intelligent
- âœ… **Google Search** : Trouve TOUTES les offres
- âœ… **Multi-sites** : Indeed, LinkedIn, Glassdoor, jobs.ch
- âœ… **Anti-dÃ©tection** : DÃ©lais, rotation User-Agent
- âœ… **Scoring** : CompatibilitÃ© personnalisÃ©e
- âœ… **DÃ©duplication** : Suppression automatique

## ğŸ¯ Workflow optimal

1. **PremiÃ¨re utilisation**
   ```bash
   ./start_web.sh
   ```

2. **Configuration**
   - Ouvrir http://localhost:5000/config
   - Adapter les critÃ¨res Ã  votre profil
   - Tester avec des critÃ¨res larges d'abord

3. **Scraping**
   - Retour sur http://localhost:5000
   - Cliquer "DÃ©marrer le scraping"
   - Attendre 30-60 minutes

4. **Analyse**
   - Consulter les rÃ©sultats dans "Offres"
   - Filtrer par score â‰¥ 70%
   - Suivre les liens vers les offres

5. **Optimisation**
   - Analyser l'historique
   - Ajuster la configuration
   - Relancer si nÃ©cessaire

## ğŸš¨ Important Ã  retenir

### FrÃ©quence d'utilisation
- **Maximum 1 fois par jour** : Ã‰viter la dÃ©tection
- **Attendre 24h** entre sessions
- **Surveiller les performances** systÃ¨me

### Maintenance
- **Sauvegarder jobs.db** : Toutes vos donnÃ©es
- **Nettoyer pÃ©riodiquement** : Supprimer anciennes sessions
- **Mettre Ã  jour** : ChromeDriver si nÃ©cessaire

### Troubleshooting
- **Port 5000 occupÃ©** : Modifier dans app.py
- **ChromeDriver manquant** : `brew install chromedriver`
- **Erreurs de config** : Valider le YAML

## ğŸ“ˆ RÃ©sultats attendus

### Performance typique
- **DurÃ©e** : 30-60 minutes
- **Offres trouvÃ©es** : 100-200
- **Offres pertinentes** : 50-100 (score â‰¥ 70%)
- **Sources** : 8-12 sites diffÃ©rents

### CompatibilitÃ©
- **90-100%** : Offres parfaites (postuler immÃ©diatement)
- **70-89%** : TrÃ¨s bonnes offres (Ã  examiner)
- **50-69%** : Offres correctes (si manque d'options)
- **<50%** : Probablement pas adaptÃ©es

## ğŸŒŸ Conseils d'optimisation

### Configuration
1. **Soyez spÃ©cifique** : Mots-clÃ©s prÃ©cis
2. **Variez les termes** : "dÃ©veloppeur", "ingÃ©nieur", "software engineer"
3. **Localisations multiples** : Suisse + France + Remote
4. **Fourchette salariale** : RÃ©aliste pour le marchÃ©

### Utilisation
1. **Analysez les tendances** : Historique des sessions
2. **Affinez progressivement** : Ajustez selon rÃ©sultats
3. **Suivez les graphiques** : Ã‰volution des performances
4. **Exportez les donnÃ©es** : CSV/Excel pour analyse

## ğŸ‰ FÃ©licitations !

Vous avez maintenant un **scraper d'emploi professionnel** qui :

âœ… **Recherche partout** : Google + tous les sites d'emploi  
âœ… **Interface moderne** : ContrÃ´le total via web  
âœ… **Base de donnÃ©es** : Persistance et historique  
âœ… **Scoring intelligent** : CompatibilitÃ© personnalisÃ©e  
âœ… **Anti-dÃ©tection** : Respectueux des serveurs  
âœ… **Multi-zones** : Suisse + France + Remote  

---

## ğŸš€ PrÃªt Ã  l'emploi !

**Lancez `./start_web.sh` et trouvez votre prochain emploi !**

ğŸ“± **Interface** : http://localhost:5000  
ğŸ”§ **Configuration** : http://localhost:5000/config  
ğŸ’¼ **Offres** : http://localhost:5000/jobs  
ğŸ“Š **Historique** : http://localhost:5000/sessions  

---

*Bon scraping et excellente recherche d'emploi ! ğŸ¯*