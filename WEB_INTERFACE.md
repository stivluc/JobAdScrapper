# üåê Interface Web - Job Ad Scraper

## üìã Pr√©sentation

L'interface web moderne du Job Ad Scraper permet de :
- **Lancer le scraping** d'un simple clic
- **Visualiser la progression** en temps r√©el
- **Consulter les r√©sultats** avec tri et filtrage
- **Modifier la configuration** avec un √©diteur int√©gr√©
- **Consulter l'historique** des sessions

## üöÄ D√©marrage rapide

### 1. Installation des d√©pendances
```bash
source job_scraper_env/bin/activate
pip install -r requirements.txt
```

### 2. Lancement de l'interface
```bash
# Sur macOS/Linux
./start_web.sh

# Sur Windows
start_web.bat

# Ou directement
python3 app.py
```

### 3. Acc√®s √† l'interface
- **Interface principale** : http://localhost:5000
- **Configuration** : http://localhost:5000/config
- **Offres d'emploi** : http://localhost:5000/jobs
- **Historique** : http://localhost:5000/sessions

## üìä Fonctionnalit√©s

### üè† Tableau de bord
- **Statistiques en temps r√©el** : Nombre d'offres, score moyen, entreprises
- **Contr√¥le du scraping** : D√©marrage, arr√™t, progression
- **Offres r√©centes** : Top 5 des meilleures offres
- **Aper√ßu des sessions** : Historique des derni√®res ex√©cutions

### üíº Gestion des offres
- **Liste pagin√©e** : Affichage optimis√© par cartes
- **Filtrage avanc√©** : Par score de compatibilit√©, date, entreprise
- **Tri personnalis√©** : Score, date, entreprise, localisation
- **Liens directs** : Acc√®s aux offres originales en un clic

### ‚öôÔ∏è Configuration
- **√âditeur YAML int√©gr√©** : Modification directe de config.yaml
- **Validation en temps r√©el** : V√©rification de la syntaxe
- **Pr√©visualisation** : Affichage des param√®tres actuels
- **Templates** : Configurations pr√©-d√©finies

### üìà Historique et statistiques
- **Sessions compl√®tes** : D√©tails de chaque ex√©cution
- **Graphiques** : √âvolution des performances
- **Analyse des erreurs** : Diagnostic et solutions
- **Export des donn√©es** : JSON, CSV, Excel

## üóÑÔ∏è Base de donn√©es SQLite

### Structure des donn√©es
```sql
-- Table des offres d'emploi
CREATE TABLE jobs (
    id INTEGER PRIMARY KEY,
    title TEXT NOT NULL,
    company TEXT NOT NULL,
    location TEXT,
    salary TEXT,
    description TEXT,
    url TEXT UNIQUE,
    source TEXT,
    match_score REAL,
    scraped_at TIMESTAMP,
    created_at TIMESTAMP
);

-- Table des sessions de scraping
CREATE TABLE scraping_sessions (
    id INTEGER PRIMARY KEY,
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    duration_seconds INTEGER,
    total_jobs INTEGER,
    unique_jobs INTEGER,
    status TEXT,
    error_message TEXT,
    config_snapshot TEXT,
    created_at TIMESTAMP
);
```

### Avantages de SQLite
- **Persistance** : Les donn√©es survivent aux red√©marrages
- **Performance** : Requ√™tes rapides avec index
- **D√©duplication** : Contraintes UNIQUE sur les URLs
- **Historique** : Suivi complet des sessions
- **Portabilit√©** : Fichier unique, facile √† sauvegarder

## üîß Configuration technique

### Port et acc√®s
- **Port par d√©faut** : 5000
- **Interface** : 0.0.0.0 (accessible depuis le r√©seau local)
- **Mode debug** : Activ√© en d√©veloppement

### S√©curit√©
- **Acc√®s local** : Interface non expos√©e publiquement
- **Validation** : Contr√¥les sur les entr√©es utilisateur
- **Timeout** : Limitation des sessions longues

### Performance
- **Pagination** : Affichage par lots (20 offres/page)
- **Cache** : Mise en cache des statistiques
- **Optimisation** : Index sur les colonnes fr√©quemment utilis√©es

## üéõÔ∏è Utilisation d√©taill√©e

### D√©marrage du scraping
1. **V√©rifier la configuration** : Page Configuration
2. **Cliquer sur "D√©marrer"** : Bouton sur le tableau de bord
3. **Suivre la progression** : Barre de progression temps r√©el
4. **Consulter les r√©sultats** : Redirection automatique

### Modification de la configuration
1. **Aller √† la page Configuration**
2. **Modifier le YAML** : √âditeur avec coloration syntaxique
3. **Valider** : Bouton de validation int√©gr√©
4. **Sauvegarder** : Prise en compte imm√©diate

### Consultation des r√©sultats
1. **Page des offres** : Liste compl√®te avec filtres
2. **Tri personnalis√©** : Par score, date, entreprise
3. **Filtrage** : Score minimum, mots-cl√©s
4. **Export** : Boutons d'export en diff√©rents formats

### Analyse des performances
1. **Page Historique** : Toutes les sessions
2. **Graphiques** : √âvolution des performances
3. **D√©tails** : Clic sur une session pour plus d'infos
4. **Diagnostic** : Messages d'erreur d√©taill√©s

## üîç API REST

### Endpoints disponibles
```
GET  /                    # Tableau de bord
GET  /jobs               # Liste des offres
GET  /config             # Configuration
POST /config/save        # Sauvegarde config
GET  /sessions           # Historique
POST /start_scraping     # D√©marrage scraping
GET  /scraping_status    # Statut temps r√©el
GET  /api/jobs           # API JSON des offres
```

### Exemple d'utilisation API
```javascript
// R√©cup√©ration des offres
fetch('/api/jobs?min_score=70&page=1')
    .then(response => response.json())
    .then(data => console.log(data.jobs));

// D√©marrage du scraping
fetch('/start_scraping', { method: 'POST' })
    .then(response => response.json())
    .then(data => console.log(data.message));
```

## üõ†Ô∏è Personnalisation

### Modification des templates
Les templates HTML sont dans `templates/` :
- `base.html` : Template principal
- `index.html` : Tableau de bord
- `jobs.html` : Liste des offres
- `config.html` : Configuration
- `sessions.html` : Historique

### Ajout de fonctionnalit√©s
1. **Nouvelles routes** : Ajouter dans `app.py`
2. **Nouveaux templates** : Cr√©er dans `templates/`
3. **Styles CSS** : Modifier dans les templates
4. **JavaScript** : Ajouter dans les templates

## üö® D√©pannage

### Probl√®mes courants

#### Port 5000 occup√©
```bash
# Changer le port dans app.py
app.run(debug=True, host='0.0.0.0', port=5001)
```

#### Erreur de base de donn√©es
```bash
# Supprimer la base et red√©marrer
rm jobs.db
python3 app.py
```

#### Templates non trouv√©s
```bash
# V√©rifier la structure des dossiers
ls -la templates/
```

#### Scraping ne d√©marre pas
1. V√©rifier ChromeDriver
2. Valider la configuration
3. Consulter les logs dans le terminal

## üéØ Conseils d'utilisation

### Optimisation
1. **Fermez les onglets inutiles** : √âconomise la m√©moire
2. **Utilisez les filtres** : Am√©liore les performances
3. **Nettoyez r√©guli√®rement** : Supprimez les anciennes sessions
4. **Monitoring** : Surveillez l'utilisation CPU/RAM

### Bonnes pratiques
1. **Sauvegardez jobs.db** : Fichier unique contenant toutes les donn√©es
2. **Testez la configuration** : Avant de lancer un scraping long
3. **Consultez l'historique** : Pour optimiser les param√®tres
4. **Utilisez les graphiques** : Pour identifier les tendances

---

**üåê Interface web pr√™te ! Lancez `./start_web.sh` et acc√©dez √† http://localhost:5000**